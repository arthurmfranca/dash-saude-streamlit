"""
ğŸ§® FERRAMENTA DE ANÃLISE ESTATÃSTICA AVANÃ‡ADA
Autor: Arthur (Estudos CiÃªncia de Dados)
Objetivo: AnÃ¡lise descritiva + testes inferenciais + ML com interpretaÃ§Ã£o automÃ¡tica
Skills: EstatÃ­stica aplicada, Streamlit, Pandas, SciPy, Scikit-learn
"""

<<<<<<< HEAD
@st.cache_data
def convert_df(df):
    return df.to_csv(index=False).encode("utf-8")

def get_csv_download_link(df):
    csv = df.to_csv(index=False).encode("utf-8")
    return csv

st.set_page_config(page_title="Dashboard Dummy", layout="wide")

st.sidebar.header("Fonte de dados")

arquivo_fato = st.sidebar.text_input(
    "Arquivo Fato CSV (pasta data/)",
    value="adesao.csv"
)

arquivo_dim = st.sidebar.text_input(
    "Arquivo DimensÃ£o CSV (opcional, pasta data/)",
    value="municipios.csv"
)

# ===== BOTÃƒO CARREGAR ARQUI () =====
if st.sidebar.button("Carregar dados", key="btn_carregar"):
    try:
        # Carrega tabela fato (obrigatÃ³ria)
        df_fato = pd.read_csv(
            f"data/{arquivo_fato}",
            encoding="utf-8",
            sep=",",
        )

        # Tabela dimensÃ£o Ã© opcional
        df_dim = None
        if arquivo_dim.strip():  # sÃ³ tenta ler se nÃ£o estiver vazio
            try:
                df_dim = pd.read_csv(
                    f"data/{arquivo_dim}",
                    encoding="utf-8",
                    sep=",",
                )
            except FileNotFoundError:
                st.sidebar.warning(f"Arquivo de dimensÃ£o nÃ£o encontrado: {arquivo_dim}. Seguindo sÃ³ com a fato.")
                df_dim = None

        # Tratamento de tipos na fato
        for col in ["Valor AdesÃ£o", "CÃ³digo IBGE", "CÃ³digo Macro"]:
            if col in df_fato.columns:
                df_fato[col] = pd.to_numeric(df_fato[col], errors="coerce")

        for col in df_fato.columns:
            if "data" in col.lower():
                df_fato[col] = pd.to_datetime(df_fato[col], dayfirst=True, errors="coerce")

        st.session_state.df_fato = df_fato
        st.session_state.df_dim = df_dim
        st.sidebar.success("Dados carregados!")
    except Exception as e:
        st.sidebar.error(f"Erro ao ler arquivos: {e}")
# ===== FIM DO BLOCO DO BOTÃƒO =====

# =====================================================
# BLOCO PRINCIPAL APÃ“S CARREGAR O CSV
# =====================================================
if "df_fato" in st.session_state:
    df_fato = st.session_state.df_fato.copy()
    df_dim = st.session_state.df_dim

    st.header("Modelo de dados (join)")

    if df_dim is not None:
        col1, col2, col3 = st.columns(3)
        with col1:
            chave_fato = st.selectbox(
                "Chave na tabela Fato",
                df_fato.columns,
                index=list(df_fato.columns).index("CÃ³digo IBGE") if "CÃ³digo IBGE" in df_fato.columns else 0,
                key="chave_fato"
            )
        with col2:
            chave_dim = st.selectbox(
                "Chave na tabela DimensÃ£o",
                df_dim.columns,
                index=list(df_dim.columns).index("CÃ³digo IBGE") if "CÃ³digo IBGE" in df_dim.columns else 0,
                key="chave_dim"
            )
        with col3:
            tipo_join = st.selectbox(
                "Tipo de junÃ§Ã£o",
                ["left", "inner"],
                key="tipo_join"
            )

        df_modelo = df_fato.merge(
            df_dim,
            left_on=chave_fato,
            right_on=chave_dim,
            how=tipo_join,
            suffixes=("_fato", "_dim")
        )
    else:
        st.info("Nenhuma tabela dimensÃ£o carregada. Usando apenas tabela fato.")
        df_modelo = df_fato

    # A partir daqui usamos df_modelo como base para filtros/medidas
    df_original = df_modelo.copy()
    st.sidebar.subheader("Filtros")
    df = df_original.copy()


# UF
    if "UF" in df.columns:
        opcoes_uf = sorted(df["UF"].dropna().unique())
        uf_sel = st.sidebar.multiselect("UF", opcoes_uf, default=opcoes_uf)
        if uf_sel:  # sÃ³ filtra se houver seleÃ§Ã£o
            df = df[df["UF"].isin(uf_sel)]
=======
import streamlit as st  # Interface web interativa
import pandas as pd     # ManipulaÃ§Ã£o de dados
import numpy as np      # CÃ¡lculos numÃ©ricos
import plotly.express as px      # GrÃ¡ficos interativos
import plotly.graph_objects as go # GrÃ¡ficos avanÃ§ados
from plotly.subplots import make_subplots  # Subplots mÃºltiplos
import scipy.stats as stats       # TESTES ESTATÃSTICOS (t-test, ANOVA, etc)
from sklearn.preprocessing import StandardScaler  # PadronizaÃ§Ã£o ML
from sklearn.decomposition import PCA            # AnÃ¡lise de componentes
from sklearn.cluster import KMeans               # Clustering
import warnings
warnings.filterwarnings('ignore')  # Remove warnings desnecessÃ¡rios

# =============================================================================
# CONFIGURAÃ‡ÃƒO DA PÃGINA (EXECUTA 1x por sessÃ£o)
# =============================================================================
st.set_page_config(
    page_title="ğŸ§® EstatÃ­stica AvanÃ§ada - Estudos", 
    layout="wide",  # Layout largo (melhor para dashboards)
    initial_sidebar_state="expanded"  # Sidebar sempre aberta
)

# FunÃ§Ã£o utilitÃ¡ria: Export CSV (cache para performance)
@st.cache_data  # ğŸš€ CACHE: executa 1x, reutiliza resultado
def convert_df(df):
    """Converte DataFrame para bytes CSV (download)"""
    return df.to_csv(index=False).encode("utf-8")

# =============================================================================
# INTERFACE PRINCIPAL
# =============================================================================
st.title("ğŸ§® Ferramenta de AnÃ¡lise EstatÃ­stica AvanÃ§ada")
st.markdown("""
**Para seus estudos de estatÃ­stica aplicada e machine learning**
- ğŸ“Š AnÃ¡lise descritiva completa
- ğŸ” CorrelaÃ§Ã£o + testes inferenciais  
- ğŸ¤– Clustering + PCA
- ğŸ’¡ InterpretaÃ§Ã£o automÃ¡tica em portuguÃªs
""")

# =====================================
# PASSO 1: UPLOAD DE DADOS
# =====================================
uploaded_file = st.file_uploader(
    "ğŸ“ Carregue sua base de dados (CSV/Excel)", 
    type=['csv','xlsx'],
    help="Qualquer dataset numÃ©rico/categÃ³rico"
)

if uploaded_file is not None:
    # Detecta formato automaticamente
    if uploaded_file.name.endswith('.csv'):
        df = pd.read_csv(uploaded_file, encoding="utf-8")
    else:
        df = pd.read_excel(uploaded_file)
    
    # âœ… CONFIRMAÃ‡ÃƒO VISUAL
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("Linhas", f"{df.shape[0]:,}")
    col2.metric("Colunas", df.shape[1])
    col3.metric("NumÃ©ricas", len(df.select_dtypes(include=[np.number]).columns))
    col4.metric("CategÃ³ricas", len(df.select_dtypes(exclude=[np.number]).columns))
    
    st.dataframe(df.head(10), use_container_width=True)

    # =====================================
    # ğŸ” DIAGNÃ“STICO AUTOMÃTICO
    # =====================================
    st.subheader("ğŸ” DiagnÃ³stico AutomÃ¡tico do Dataset")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.write("**ğŸ“‹ Todas as colunas:**")
        for i, col in enumerate(df.columns):
            st.write(f"{i+1}. **{col}** ({df[col].dtype})")
    with col2:
        st.write("**ğŸ”¢ Colunas NumÃ©ricas:**")
        num_cols_diag = df.select_dtypes(include=[np.number]).columns.tolist()
        for col in num_cols_diag:
            st.write(f"â€¢ {col}")
    with col3:
        st.write("**ğŸ·ï¸ Colunas CategÃ³ricas:**")
        cat_cols_diag = df.select_dtypes(exclude=[np.number]).columns.tolist()
        for col in cat_cols_diag:
            st.write(f"â€¢ {col}")
    # FIM DIAGNÃ“STICO
    
    # =====================================
    # PASSO 2: MENU LATERAL - SELEÃ‡ÃƒO DE ANÃLISES
    # =====================================
    st.sidebar.header("ğŸ” Escolha sua AnÃ¡lise")
    analise_tipo = st.sidebar.selectbox("Tipo de anÃ¡lise", [
    "ğŸ“Š 1. AnÃ¡lise Descritiva", 
    "ğŸ”— 2. CorrelaÃ§Ã£o", 
    "ğŸ¥ 3. AnÃ¡lise SaÃºde",           # â† ADICIONE ESTA LINHA
    "ğŸ“ˆ 4. Testes EstatÃ­sticos", 
    "ğŸ­ 5. Clustering K-Means",
    "ğŸ“‰ 6. PCA (ReduÃ§Ã£o Dimensional)"
    ])

    # =====================================
    # VARIÃVEIS GLOBAIS (CORREÃ‡ÃƒO DO ERRO)
    # =====================================
    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    cat_cols = df.select_dtypes(exclude=[np.number]).columns.tolist()
>>>>>>> 88a5fd1 (feat: ferramenta estatÃ­stica COMPLETA v3.0)


    
    # =====================================
    # ANÃLISE 1: DESCRITIVA (ESTATÃSTICAS BÃSICAS)
    # =====================================
    if analise_tipo == "ğŸ“Š 1. AnÃ¡lise Descritiva":
        st.header("ğŸ“Š 1. AnÃ¡lise Descritiva Completa")
        st.markdown("**CONCEITO:** Resumo estatÃ­stico + normalidade + visualizaÃ§Ãµes diagnÃ³sticas")
        
        # Seleciona variÃ¡veis numÃ©ricas
        num_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        col1, col2 = st.columns(2)
        
        with col1:
            vars_analise = st.multiselect(
                "ğŸ”¢ VariÃ¡veis para anÃ¡lise", 
                num_cols, 
                default=num_cols[:3]  # Pega primeiras 3 automaticamente
            )
        with col2:
            var_alvo = st.selectbox("ğŸ“ VariÃ¡vel alvo (grÃ¡ficos)", num_cols)
        
        if st.button("ğŸ”¬ Executar AnÃ¡lise Descritiva", type="primary") and vars_analise:
            st.subheader("ğŸ“ˆ Tabela de EstatÃ­sticas Descritivas")
            
            # Tabela completa (transposta para melhor visualizaÃ§Ã£o)
            desc_stats = df[vars_analise].describe().round(3).T
            st.dataframe(desc_stats, use_container_width=True)
            
            # ğŸ’¡ INTERPRETAÃ‡ÃƒO AUTOMÃTICA
            st.subheader("ğŸ’¡ InterpretaÃ§Ã£o EstatÃ­stica AutomÃ¡tica")
            for var in vars_analise:
                # CÃ¡lculos chave
                media = df[var].mean()
                dp = df[var].std()
                cv = (dp/media)*100 if media != 0 else 0  # Coeficiente de variaÃ§Ã£o
                
                # Teste de normalidade (Shapiro-Wilk)
                stat, p_shapiro = stats.shapiro(df[var].dropna()[:5000])  # Limita amostra
                
                col1, col2, col3 = st.columns(3)
                col1.metric("MÃ©dia", f"{media:.2f}")
                col2.metric("DP", f"{dp:.2f}")
                col3.metric("CV%", f"{cv:.1f}%")
                
                # InterpretaÃ§Ã£o normalidade
                if p_shapiro < 0.05:
                    st.error(f"âŒ **{var}:** NÃ£o normal (Shapiro p={p_shapiro:.4f})")
                    st.info("â†’ Use testes nÃ£o-paramÃ©tricos (Mann-Whitney, Kruskal-Wallis)")
                else:
                    st.success(f"âœ… **{var}:** Normal (Shapiro p={p_shapiro:.4f})")
                    st.info("â†’ Use testes paramÃ©tricos (t-test, ANOVA)")
            
            # ğŸ“Š VISUALIZAÃ‡Ã•ES DIAGNÃ“STICAS
            st.subheader("ğŸ“Š VisualizaÃ§Ãµes DiagnÃ³sticas")
            fig = make_subplots(
                rows=2, cols=2,
                subplot_titles=('ğŸ“ˆ Histograma', 'ğŸ“¦ Boxplot', 'ğŸ“Š QQ-Plot Normalidade', 'ğŸ² Densidade'),
                specs=[[{"secondary_y": False}, {"secondary_y": False}],
                       [{"secondary_y": False}, {"secondary_y": False}]]
            )
            
            # Histograma
            fig.add_trace(go.Histogram(x=df[var_alvo], name="Histograma", nbinsx=30), row=1, col=1)
            
            # Boxplot
            fig.add_trace(go.Box(y=df[var_alvo], name="Boxplot"), row=1, col=2)
            
            # QQ-Plot (diagnÃ³stico normalidade)
            try:
                from scipy.stats import norm, probplot
                qq_data = df[var_alvo].dropna()
                (osm, osr), (slope, intercept, r) = probplot(qq_data, dist="norm", plot=False)
                fig.add_trace(go.Scatter(x=osm, y=osr, mode='markers+lines', 
                           name="QQ-Plot", line=dict(color='blue')), row=2, col=1)
            except:
                fig.add_trace(go.Scatter(x=[0,1], y=[0,1], mode='lines', 
                           name="QQ-Plot (simplificado)"), row=2, col=1)
            # KDE (densidade)
            fig.add_trace(go.Histogram(x=df[var_alvo], histnorm='probability density'), row=2, col=2)
            
            fig.update_layout(height=600, showlegend=False, title_text="DiagnÃ³sticos Visuais")
            st.plotly_chart(fig, use_container_width=True)
    
    # =====================================
    # ANÃLISE 2: CORRELAÃ‡ÃƒO
    # =====================================
    elif analise_tipo == "ğŸ”— 2. CorrelaÃ§Ã£o":
        st.header("ğŸ”— 2. Matriz de CorrelaÃ§Ã£o")
        st.markdown("""
        **CONCEITO:** Mede relaÃ§Ã£o linear entre variÃ¡veis (Pearson r âˆˆ [-1,1])
        - **r > 0.7 ou r < -0.7:** CorrelaÃ§Ã£o forte
        - **p-valor < 0.05:** Significativa estatisticamente
        """)
        
        num_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        
        if len(num_cols) >= 2 and st.button("ğŸ”— Calcular CorrelaÃ§Ã£o", type="primary"):
            # Matriz Pearson
            corr_matrix = df[num_cols].corr()
            
            # Heatmap interativo
            fig = px.imshow(
                corr_matrix.round(3),
                title="ğŸ”¥ Matriz de CorrelaÃ§Ã£o Pearson",
                color_continuous_scale='RdBu_r',  # Vermelho=negativo, Azul=positivo
                aspect="auto"
            )
            st.plotly_chart(fig, use_container_width=True)
            
            # CorrelaÃ§Ãµes fortes
            st.subheader("ğŸš¨ CorrelaÃ§Ãµes Fortes |r| > 0.7")
            mask = (abs(corr_matrix) > 0.7) & (corr_matrix != 1.0)
            strong_corr = corr_matrix[mask].stack().reset_index()
            strong_corr.columns = ['VariÃ¡vel 1', 'VariÃ¡vel 2', 'r_Pearson']
            strong_corr['ForÃ§a'] = pd.cut(abs(strong_corr['r_Pearson']), 
                                        bins=[0.7, 0.8, 0.9, 1], 
                                        labels=['Forte', 'Muito Forte', 'Perfeita'])
            st.dataframe(strong_corr.round(3))

    # =====================================
    # ANÃLISE 3: DENGUE/SAÃšDE PÃšBLICA
    # =====================================

    elif analise_tipo == "ğŸ¥ 3. AnÃ¡lise SaÃºde":
        st.header("ğŸ¥ 3. AnÃ¡lise SaÃºde - TOP RegiÃµes")
        
        num_cols = df.select_dtypes(include=[np.number]).columns
        cat_cols = df.select_dtypes(exclude=[np.number]).columns
        
        col1, col2 = st.columns(2)
        with col1:
            col_casos = st.selectbox("ğŸ“Š Casos/Ã“bitos", num_cols)
        with col2:
            col_regiao = st.selectbox("ğŸ›ï¸ MunicÃ­pio/UF", cat_cols)
        
        if st.button("ğŸš¨ TOP 10 RegiÃµes", type="primary"):
            # TOP 10 genÃ©rico
            top10 = df.nlargest(10, col_casos)[[col_regiao, col_casos]].round(1)
            top10.columns = ['RegiÃ£o', 'Valor']
            
            st.subheader("ğŸ”¥ TOP 10 RegiÃµes MAIS AFETADAS")
            st.dataframe(top10, use_container_width=True)
            
            # GrÃ¡fico
            fig = px.bar(top10, x='RegiÃ£o', y='Valor', 
                        title=f"TOP 10 - {col_casos}", 
                        color='Valor')
            st.plotly_chart(fig, use_container_width=True)
    
    # =====================================
    # ANÃLISE 4: TESTES ESTATÃSTICOS (CORRIGIDO)
    # =====================================
    elif analise_tipo == "ğŸ“ˆ 4. Testes EstatÃ­sticos":
        st.header("ğŸ“ˆ 4. Testes Inferenciais")
        st.markdown("**CONCEITO:** Verifica hipÃ³teses (H0 vs H1) com p-valor < 0.05")
        
        col1, col2 = st.columns(2)
        with col1:
            teste_tipo = st.selectbox("Teste", ["t-test (2 grupos)", "ANOVA (3+ grupos)", "Qui-Quadrado"])
        with col2:
            var_resposta = st.selectbox("ğŸ“Š VariÃ¡vel numÃ©rica", num_cols)
        
        if teste_tipo == "t-test (2 grupos)" and st.button("ğŸ”¬ Executar t-test", type="primary"):
            grupo_var = st.selectbox("ğŸ·ï¸ VariÃ¡vel grupos", cat_cols)
            grupos = df[grupo_var].dropna().unique()[:2]  # Primeiros 2 grupos
            
            if len(grupos) >= 2:
                grupo1 = df[df[grupo_var] == grupos[0]][var_resposta].dropna()
                grupo2 = df[df[grupo_var] == grupos[1]][var_resposta].dropna()
                
                if len(grupo1) > 1 and len(grupo2) > 1:
                    t_stat, p_val = stats.ttest_ind(grupo1, grupo2)
                    
                    col1, col2 = st.columns(2)
                    col1.metric("ğŸ“Š t-statistic", f"{t_stat:.3f}")
                    col2.metric("ğŸ¯ p-valor", f"{p_val:.4f}")
                    
                    st.subheader("ğŸ’¡ InterpretaÃ§Ã£o")
                    if p_val < 0.05:
                        st.error(f"ğŸš¨ **REJEITA H0** (p={p_val:.4f})")
                        st.success(f"âœ… {grupos[0]} **â‰ ** {grupos[1]} em {var_resposta}")
                    else:
                        st.info(f"â„¹ï¸ **NÃƒO rejeita H0** (p={p_val:.4f})")
                        st.warning(f"{grupos[0]} **â‰ˆ** {grupos[1]} em {var_resposta}")
                else:
                    st.warning("âŒ Poucos dados em um dos grupos")
            else:
                st.warning("â“ Selecione variÃ¡vel com â‰¥2 grupos")

    elif analise_tipo == "ğŸ­ 5. Clustering K-Means":
        st.header("ğŸ­ 5. Clustering AutomÃ¡tico")
        st.markdown("**CONCEITO:** Agrupa observaÃ§Ãµes similares automaticamente")
        
        vars_cluster = st.multiselect("ğŸ”¢ VariÃ¡veis para cluster", num_cols, default=num_cols[:3])
        n_clusters = st.slider("NÃºmero de clusters", 2, 8, 4)
        
        if st.button("ğŸ¤– Executar Clustering", type="primary") and len(vars_cluster)>=2:
            # Padroniza + clusteriza
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(df[vars_cluster].dropna())
            
            kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
            clusters = kmeans.fit_predict(X_scaled)
            
            df_cluster = df.dropna(subset=vars_cluster).copy()
            df_cluster['Cluster'] = clusters
            
            st.subheader("ğŸ“Š Resultado Clustering")
            st.dataframe(df_cluster.groupby('Cluster')[vars_cluster].mean().round(2))
            
            # GrÃ¡fico 2D
            fig = px.scatter(df_cluster, x=vars_cluster[0], y=vars_cluster[1], 
                            color='Cluster', title="Clusters AutomÃ¡ticos")
            st.plotly_chart(fig)
            
    elif analise_tipo == "ğŸ“‰ 6. PCA (ReduÃ§Ã£o Dimensional)":
        st.header("ğŸ“‰ 6. PCA - ReduÃ§Ã£o Dimensional")
        vars_pca = st.multiselect("ğŸ”¢ VariÃ¡veis", num_cols, default=num_cols[:4])
        
        if st.button("ğŸ“‰ Executar PCA", type="primary") and len(vars_pca)>=2:
            from sklearn.decomposition import PCA
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(df[vars_pca].dropna())
            
            pca = PCA()
            X_pca = pca.fit_transform(X_scaled)
            
            st.subheader("ğŸ“Š VariÃ¢ncia Explicada")
            var_exp = pd.DataFrame({
                'Componente': [f'PC{i+1}' for i in range(len(pca.explained_variance_ratio_))],
                'VariÃ¢ncia %': (pca.explained_variance_ratio_*100).round(1)
            })
            st.dataframe(var_exp)
            
            fig = px.scatter(x=X_pca[:,0], y=X_pca[:,1], 
                            title="PCA 2D - Primeiros 2 Componentes")
            st.plotly_chart(fig)


<<<<<<< HEAD
    # -------------------------
    # PRÃ‰-VISUALIZAÃ‡ÃƒO JÃ FILTRADA
    # -------------------------
    st.write("Tipos das colunas (apÃ³s conversÃ£o):")
    st.write(df.dtypes)

    st.header("PrÃ©-visualizaÃ§Ã£o dos dados filtrados")
    st.dataframe(df.head())

    # -------------------------
    # EXPORTAR DADOS FILTRADOS PARA CSV
    # -------------------------
    st.subheader("Exportar dados")

    csv_bytes = convert_df(df)

    st.download_button(
        label="Baixar dados filtrados em CSV",
        data=csv_bytes,
        file_name="dados_filtrados.csv",
        mime="text/csv",
        key="download_csv_filtrado"
    )


    # -------------------------
    # MEDIDAS (usando df FILTRADO)
    # -------------------------
    st.header("Medidas (tipo DAX)")

    num_cols = df.select_dtypes(include=["number"]).columns
    cat_cols = df.select_dtypes(exclude=["number", "datetime64[ns]"]).columns

    col_m1, col_m2, col_m3 = st.columns(3)
    with col_m1:
        medida_tipo = st.selectbox(
            "Tipo de medida",
            [
                "SUM",
                "AVG",
                "COUNT",
                "DISTINCT COUNT",
                "% do total por categoria",
                "TOP N",
                "Taxa (num/denom) x K"
            ],
            key="tipo_medida"
        )
    
    with col_m2:
        medida_coluna = st.selectbox("Coluna numÃ©rica", num_cols, key="coluna_medida")
    with col_m3:
        medida_nome = st.text_input("Nome da medida", value="Medida_1", key="nome_medida")

    num_cols = df.select_dtypes(include=["number"]).columns
    cat_cols = df.select_dtypes(exclude=["number", "datetime64[ns]"]).columns

    cat_group = None
    top_n = None
    num_col_taxa = None
    den_col_taxa = None
    k_const = None

    if medida_tipo == "% do total por categoria":
        cat_group = st.selectbox("Agrupar por (categoria)", cat_cols, key="cat_group")

    if medida_tipo == "TOP N":
        top_n = st.number_input("Valor de N (Top N)", min_value=1, value=10, key="top_n_val")

    if medida_tipo == "Taxa (num/denom) x K":
        num_col_taxa = st.selectbox("Coluna numerador", num_cols, key="num_col_taxa")
        den_col_taxa = st.selectbox("Coluna denominador", num_cols, key="den_col_taxa")
        k_const = st.number_input("Constante K (ex.: 1000, 100000)", min_value=1.0, value=100000.0, key="k_const")

    if st.button("Calcular medida", key="btn_calc_medida"):
        df_result = None

        if medida_tipo == "SUM":
            valor = df[medida_coluna].sum()
            df_result = pd.DataFrame({medida_nome: [valor]})

        elif medida_tipo == "AVG":
            valor = df[medida_coluna].mean()
            df_result = pd.DataFrame({medida_nome: [valor]})

        elif medida_tipo == "COUNT":
            valor = df[medida_coluna].count()
            df_result = pd.DataFrame({medida_nome: [valor]})

        elif medida_tipo == "DISTINCT COUNT":
            valor = df[medida_coluna].nunique()
            df_result = pd.DataFrame({medida_nome: [valor]})

        elif medida_tipo == "% do total por categoria" and cat_group is not None:
            agrupado = df.groupby(cat_group, as_index=False)[medida_coluna].sum()
            total = agrupado[medida_coluna].sum()
            agrupado[medida_nome] = agrupado[medida_coluna] / total * 100
            df_result = agrupado

        elif medida_tipo == "TOP N" and top_n is not None:
            df_result = df.nlargest(top_n, medida_coluna)

        elif medida_tipo == "Taxa (num/denom) x K" and num_col_taxa and den_col_taxa and k_const:
        # soma numerador e denominador (agregaÃ§Ã£o global)
            num = df[num_col_taxa].sum()
            den = df[den_col_taxa].sum()

            if den == 0 or pd.isna(den):
                taxa = None
            else:
                taxa = num / den * k_const

            df_result = pd.DataFrame({
                "Numerador": [num],
                "Denominador": [den],
                f"Taxa_{medida_nome}": [taxa],
                "K": [k_const]
            })

        if df_result is not None:
            st.subheader("Resultado da medida")
            st.dataframe(df_result)

            st.session_state.df_medida = df_result

            st.subheader("Exportar resultado da medida")

            if "df_medida" in st.session_state:
                csv_medida = convert_df(st.session_state.df_medida)

                st.download_button(
                    label="Baixar resultado da medida (CSV)",
                    data=csv_medida,
                    file_name="resultado_medida.csv",
                    mime="text/csv",
                    key="download_medida_csv"
                )

            else:
                st.info("Nenhuma medida calculada ainda.")    

    # -------------------------
    # GRÃFICO RÃPIDO (df filtrado)
    # -------------------------
    st.header("GrÃ¡fico rÃ¡pido")

    num_cols = df.select_dtypes(include=["number"]).columns
    if len(num_cols) == 0:
        st.info("NÃ£o hÃ¡ colunas numÃ©ricas para grÃ¡fico.")
    else:
        col_g1, col_g2 = st.columns(2)
        with col_g1:
            x_col = st.selectbox("Eixo X", df.columns, key="x_col")
        with col_g2:
            y_col = st.selectbox("Eixo Y (numÃ©rico)", num_cols, key="y_col")

        tipo_graf = st.selectbox(
            "Tipo de grÃ¡fico",
            ["Barra", "Linha", "Pizza", "Scatter"],
            key="tipo_grafico"
        )


        if st.button("Gerar grÃ¡fico", key="btn_grafico"):
            if tipo_graf == "Barra":
                fig = px.bar(df, x=x_col, y=y_col)
            elif tipo_graf == "Linha":
                fig = px.line(df, x=x_col, y=y_col)
            elif tipo_graf == "Pizza":
                fig = px.pie(df, names=x_col, values=y_col)
            elif tipo_graf == "Scatter":
                fig = px.scatter(df, x=x_col, y=y_col)

            st.plotly_chart(fig, use_container_width=True)

=======
   
    # =====================================
    # BARRA LATERAL: EXPORT
    # =====================================
    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸ’¾ Exportar")
    csv_bytes = convert_df(df)
    st.sidebar.download_button(
        "ğŸ“¥ Dados Originais CSV",
        csv_bytes,
        "dados_originais.csv",
        "text/csv"
    )

# =====================================
# ESTADO INICIAL (SEM DADOS)
# =====================================
>>>>>>> 88a5fd1 (feat: ferramenta estatÃ­stica COMPLETA v3.0)
else:
    st.info("""
    ğŸ‘† **Carregue um dataset CSV/Excel para comeÃ§ar!**
    
    **Exemplos recomendados para estudo:**
    - Iris (classificaÃ§Ã£o)
    - Boston Housing (regressÃ£o)  
    - Titanic (anÃ¡lise exploratÃ³ria)
    - Qualquer base com â‰¥3 colunas numÃ©ricas
    """)
