"""
ğŸ§® FERRAMENTA DE ANÃLISE ESTATÃSTICA AVANÃ‡ADA
Autor: Arthur (Estudos CiÃªncia de Dados)
Objetivo: AnÃ¡lise descritiva + testes inferenciais + ML com interpretaÃ§Ã£o automÃ¡tica
Skills: EstatÃ­stica aplicada, Streamlit, Pandas, SciPy, Scikit-learn
"""


import streamlit as st  # Interface web interativa
import pandas as pd     # ManipulaÃ§Ã£o de dados
import numpy as np      # CÃ¡lculos numÃ©ricos
import plotly.express as px      # GrÃ¡ficos interativos
import plotly.graph_objects as go # GrÃ¡ficos avanÃ§ados
from plotly.subplots import make_subplots  # Subplots mÃºltiplos
import scipy.stats as stats       # TESTES ESTATÃSTICOS (t-test, ANOVA, etc)
from sklearn.preprocessing import StandardScaler  # PadronizaÃ§Ã£o ML
from sklearn.decomposition import PCA            # AnÃ¡lise de componentes
from sklearn.cluster import KMeans               # Clustering
import warnings
warnings.filterwarnings('ignore')  # Remove warnings desnecessÃ¡rios


# =============================================================================
# CONFIGURAÃ‡ÃƒO DA PÃGINA (EXECUTA 1x por sessÃ£o)
# =============================================================================
st.set_page_config(
    page_title="ğŸ§® EstatÃ­stica AvanÃ§ada - Estudos", 
    layout="wide",  # Layout largo (melhor para dashboards)
    initial_sidebar_state="expanded"  # Sidebar sempre aberta
)

# FunÃ§Ã£o utilitÃ¡ria: Export CSV (cache para performance)
@st.cache_data  # ğŸš€ CACHE: executa 1x, reutiliza resultado
def convert_df(df):
    """Converte DataFrame para bytes CSV (download)"""
    return df.to_csv(index=False).encode("utf-8")

@st.cache_data
def compute_descritiva(df, vars_analise):
    """Cache estatÃ­sticas descritivas"""
    return df[vars_analise].describe().round(3)

@st.cache_data
def compute_correlacao(df, num_cols):
    """Cache matriz correlaÃ§Ã£o"""
    return df[num_cols].corr()

@st.cache_data
def top_regioes(df, col_casos, col_regiao):
    return df.nlargest(10, col_casos)[[col_regiao, col_casos]].round(1)
    
# =============================================================================
# INTERFACE PRINCIPAL
# =============================================================================
st.title("ğŸ§® Ferramenta de AnÃ¡lise EstatÃ­stica AvanÃ§ada")
st.markdown("""
**Para seus estudos de estatÃ­stica aplicada e machine learning**
- ğŸ“Š AnÃ¡lise descritiva completa
- ğŸ” CorrelaÃ§Ã£o + testes inferenciais  
- ğŸ¤– Clustering + PCA
- ğŸ’¡ InterpretaÃ§Ã£o automÃ¡tica em portuguÃªs
""")


# =====================================
# PASSO 1: UPLOAD DE DADOS
# =====================================
uploaded_file = st.file_uploader(
    "ğŸ“ Carregue sua base de dados (CSV/Excel)", 
    type=['csv','xlsx'],
    help="Qualquer dataset numÃ©rico/categÃ³rico"
)


# Permite usar dataset gerado via botÃ£o de teste (Iris)
if uploaded_file is not None or 'uploaded_df' in st.session_state:
    # Fonte: upload de arquivo ou dataset gerado em sessÃ£o
    if 'uploaded_df' in st.session_state:
        df = st.session_state['uploaded_df']
    else:
        # Detecta formato automaticamente
        if uploaded_file.name.endswith('.csv'):
            df = pd.read_csv(uploaded_file, encoding="utf-8")
        else:
            df = pd.read_excel(uploaded_file)

    # =====================================
    # VARIÃVEIS GLOBAIS
    # =====================================
    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    cat_cols = df.select_dtypes(exclude=[np.number]).columns.tolist()
    
    # âœ… CONFIRMAÃ‡ÃƒO VISUAL
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("Linhas", f"{df.shape[0]:,}")
    col2.metric("Colunas", df.shape[1])
    col3.metric("NumÃ©ricas", len(df.select_dtypes(include=[np.number]).columns))
    col4.metric("CategÃ³ricas", len(df.select_dtypes(exclude=[np.number]).columns))
    
    st.dataframe(df.head(10), width="stretch")


    # =====================================
    # ğŸ” DIAGNÃ“STICO AUTOMÃTICO
    # =====================================
    st.subheader("ğŸ” DiagnÃ³stico AutomÃ¡tico do Dataset")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.write("**ğŸ“‹ Todas as colunas:**")
        for i, col in enumerate(df.columns):
            st.write(f"{i+1}. **{col}** ({df[col].dtype})")
    with col2:
        st.write("**ğŸ”¢ Colunas NumÃ©ricas:**")
        num_cols_diag = df.select_dtypes(include=[np.number]).columns.tolist()
        for col in num_cols_diag:
            st.write(f"â€¢ {col}")
    with col3:
        st.write("**ğŸ·ï¸ Colunas CategÃ³ricas:**")
        cat_cols_diag = df.select_dtypes(exclude=[np.number]).columns.tolist()
        for col in cat_cols_diag:
            st.write(f"â€¢ {col}")
    # FIM DIAGNÃ“STICO
    
    # =====================================
    # PASSO 2: MENU LATERAL - SELEÃ‡ÃƒO DE ANÃLISES
    # =====================================
    st.sidebar.header("ğŸ” Escolha sua AnÃ¡lise")
    analise_tipo = st.sidebar.selectbox("Tipo de anÃ¡lise", [
    "ğŸ“Š 1. AnÃ¡lise Descritiva", 
    "ğŸ”— 2. CorrelaÃ§Ã£o", 
    "ğŸ¥ 3. AnÃ¡lise SaÃºde",           # â† ADICIONE ESTA LINHA
    "ğŸ“ˆ 4. Testes EstatÃ­sticos", 
    "ğŸ­ 5. Clustering K-Means",
    "ğŸ“‰ 6. PCA (ReduÃ§Ã£o Dimensional)"
    ])


    
    # =====================================
    # ANÃLISE 1: DESCRITIVA (ESTATÃSTICAS BÃSICAS)
    # =====================================
    if analise_tipo == "ğŸ“Š 1. AnÃ¡lise Descritiva":
        st.header("ğŸ“Š 1. AnÃ¡lise Descritiva Completa")
        st.markdown("**CONCEITO:** Resumo estatÃ­stico + normalidade + visualizaÃ§Ãµes diagnÃ³sticas")
        
        # Seleciona variÃ¡veis numÃ©ricas
        num_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        col1, col2 = st.columns(2)
        
        with col1:
            vars_analise = st.multiselect(
                "ğŸ”¢ VariÃ¡veis para anÃ¡lise", 
                num_cols, 
                default=num_cols[:3]  # Pega primeiras 3 automaticamente
            )
        with col2:
            var_alvo = st.selectbox("ğŸ“ VariÃ¡vel alvo (grÃ¡ficos)", num_cols)
        
        if st.button("ğŸ”¬ Executar AnÃ¡lise Descritiva", type="primary") and vars_analise:
            st.subheader("ğŸ“ˆ Tabela de EstatÃ­sticas Descritivas")
            
            # Tabela completa (transposta para melhor visualizaÃ§Ã£o)
            desc_stats = compute_descritiva(df, vars_analise)
            st.dataframe(desc_stats, width="stretch")
            
            # ğŸ’¡ INTERPRETAÃ‡ÃƒO AUTOMÃTICA
            st.subheader("ğŸ’¡ InterpretaÃ§Ã£o EstatÃ­stica AutomÃ¡tica")
            for var in vars_analise:
                # CÃ¡lculos chave
                media = df[var].mean()
                dp = df[var].std()
                cv = (dp/media)*100 if media != 0 else 0  # Coeficiente de variaÃ§Ã£o
                
                # Teste de normalidade (Shapiro-Wilk)
                stat, p_shapiro = stats.shapiro(df[var].dropna()[:5000])  # Limita amostra
                
                col1, col2, col3 = st.columns(3)
                col1.metric("MÃ©dia", f"{media:.2f}")
                col2.metric("DP", f"{dp:.2f}")
                col3.metric("CV%", f"{cv:.1f}%")
                
                # InterpretaÃ§Ã£o normalidade
                if p_shapiro < 0.05:
                    st.error(f"âŒ **{var}:** NÃ£o normal (Shapiro p={p_shapiro:.4f})")
                    st.info("â†’ Use testes nÃ£o-paramÃ©tricos (Mann-Whitney, Kruskal-Wallis)")
                else:
                    st.success(f"âœ… **{var}:** Normal (Shapiro p={p_shapiro:.4f})")
                    st.info("â†’ Use testes paramÃ©tricos (t-test, ANOVA)")
            
            # ğŸ“Š VISUALIZAÃ‡Ã•ES DIAGNÃ“STICAS
            st.subheader("ğŸ“Š VisualizaÃ§Ãµes DiagnÃ³sticas")
            fig = make_subplots(
                rows=2, cols=2,
                subplot_titles=('ğŸ“ˆ Histograma', 'ğŸ“¦ Boxplot', 'ğŸ“Š QQ-Plot Normalidade', 'ğŸ² Densidade'),
                specs=[[{"secondary_y": False}, {"secondary_y": False}],
                       [{"secondary_y": False}, {"secondary_y": False}]]
            )
            
            # Histograma
            fig.add_trace(go.Histogram(x=df[var_alvo], name="Histograma", nbinsx=30), row=1, col=1)
            
            # Boxplot
            fig.add_trace(go.Box(y=df[var_alvo], name="Boxplot"), row=1, col=2)
            
            # QQ-Plot (diagnÃ³stico normalidade)
            try:
                from scipy.stats import norm, probplot
                qq_data = df[var_alvo].dropna()
                (osm, osr), (slope, intercept, r) = probplot(qq_data, dist="norm", plot=False)
                fig.add_trace(go.Scatter(x=osm, y=osr, mode='markers+lines', 
                           name="QQ-Plot", line=dict(color='blue')), row=2, col=1)
            except:
                fig.add_trace(go.Scatter(x=[0,1], y=[0,1], mode='lines', 
                           name="QQ-Plot (simplificado)"), row=2, col=1)
            # KDE (densidade)
            fig.add_trace(go.Histogram(x=df[var_alvo], histnorm='probability density'), row=2, col=2)
            
            fig.update_layout(height=600, showlegend=False, title_text="DiagnÃ³sticos Visuais")
            st.plotly_chart(fig, width="stretch")
    
    # =====================================
    # ANÃLISE 2: CORRELAÃ‡ÃƒO
    # =====================================
    elif analise_tipo == "ğŸ”— 2. CorrelaÃ§Ã£o":
        st.header("ğŸ”— 2. Matriz de CorrelaÃ§Ã£o")
        st.markdown("""
        **CONCEITO:** Mede relaÃ§Ã£o linear entre variÃ¡veis (Pearson r âˆˆ [-1,1])
        - **r > 0.7 ou r < -0.7:** CorrelaÃ§Ã£o forte
        - **p-valor < 0.05:** Significativa estatisticamente
        """)
        
        num_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        
        if len(num_cols) >= 2 and st.button("ğŸ”— Calcular CorrelaÃ§Ã£o", type="primary"):
            # Matriz Pearson
            corr_matrix = compute_correlacao(df, num_cols)
            
            # Heatmap interativo
            fig = px.imshow(
                corr_matrix.round(3),
                title="ğŸ”¥ Matriz de CorrelaÃ§Ã£o Pearson",
                color_continuous_scale='RdBu_r',  # Vermelho=negativo, Azul=positivo
                aspect="auto"
            )
            st.plotly_chart(fig, width="stretch")
            
            # CorrelaÃ§Ãµes fortes
            st.subheader("ğŸš¨ CorrelaÃ§Ãµes Fortes |r| > 0.7")
            mask = (abs(corr_matrix) > 0.7) & (corr_matrix != 1.0)
            strong_corr = corr_matrix[mask].stack().reset_index()
            strong_corr.columns = ['VariÃ¡vel 1', 'VariÃ¡vel 2', 'r_Pearson']
            strong_corr['ForÃ§a'] = pd.cut(abs(strong_corr['r_Pearson']), 
                                        bins=[0.7, 0.8, 0.9, 1], 
                                        labels=['Forte', 'Muito Forte', 'Perfeita'])
            st.dataframe(strong_corr.round(3))


    # ANÃLISE 3: DENGUE/SAÃšDE PÃšBLICA
    elif analise_tipo == "ğŸ¥ 3. AnÃ¡lise SaÃºde":
        st.header("ğŸ¥ 3. AnÃ¡lise SaÃºde - TOP RegiÃµes")
        
        num_cols = df.select_dtypes(include=[np.number]).columns
        cat_cols = df.select_dtypes(exclude=[np.number]).columns
        
        col1, col2 = st.columns(2)
        with col1:
            col_casos = st.selectbox("ğŸ“Š Casos/Ã“bitos", num_cols)
        with col2:
            col_regiao = st.selectbox("ğŸ›ï¸ MunicÃ­pio/UF", cat_cols)
            
        
        if st.button("ğŸš¨ TOP 10 RegiÃµes", type="primary"):
            # TOP 10 genÃ©rico
            top10 = top_regioes(df, col_casos, col_regiao)
            top10.columns = ['RegiÃ£o', 'Valor']
            
            st.subheader("ğŸ”¥ TOP 10 RegiÃµes MAIS AFETADAS")
            st.dataframe(top10, width="stretch")
            
            # GrÃ¡fico
            fig = px.bar(top10, x='RegiÃ£o', y='Valor', 
                        title=f"TOP 10 - {col_casos}", 
                        color='Valor')
            st.plotly_chart(fig, width="stretch")

    # =====================================
    # ANÃLISE 4: TESTES ESTATÃSTICOS
    # =====================================
    elif analise_tipo == "ğŸ“ˆ 4. Testes EstatÃ­sticos":
        st.header("ğŸ“ˆ 4. Testes Inferenciais")
        st.markdown("**CONCEITO:** Verifica hipÃ³teses (H0 vs H1) com p-valor < 0.05")
        
        col1, col2 = st.columns(2)
        with col1:
            teste_tipo = st.selectbox("Teste", ["t-test (2 grupos)", "ANOVA (3+ grupos)", "Qui-Quadrado"])
        with col2:
            var_resposta = st.selectbox("ğŸ“Š VariÃ¡vel numÃ©rica", num_cols)
        
        if teste_tipo == "t-test (2 grupos)":
            grupo_var = st.selectbox("ğŸ·ï¸ VariÃ¡vel grupos", cat_cols)
            if st.button("ğŸ”¬ Executar t-test", type="primary"):
                grupos = df[grupo_var].dropna().unique()[:2]
                if len(grupos) >= 2:
                    grupo1 = df[df[grupo_var] == grupos[0]][var_resposta].dropna()
                    grupo2 = df[df[grupo_var] == grupos[1]][var_resposta].dropna()
                    
                    if len(grupo1) > 1 and len(grupo2) > 1:
                        t_stat, p_val = stats.ttest_ind(grupo1, grupo2)
                        
                        col1, col2 = st.columns(2)
                        col1.metric("ğŸ“Š t-statistic", f"{t_stat:.3f}")
                        col2.metric("ğŸ¯ p-valor", f"{p_val:.4f}")
                        
                        st.subheader("ğŸ’¡ InterpretaÃ§Ã£o")
                        if p_val < 0.05:
                            st.error(f"ğŸš¨ **REJEITA H0** (p={p_val:.4f})")
                            st.success(f"âœ… {grupos[0]} **â‰ ** {grupos[1]} em {var_resposta}")
                        else:
                            st.info(f"â„¹ï¸ **NÃƒO rejeita H0** (p={p_val:.4f})")
                            st.warning(f"{grupos[0]} **â‰ˆ** {grupos[1]} em {var_resposta}")
                    else:
                        st.warning("âŒ Poucos dados em um dos grupos")
                else:
                    st.warning("â“ Selecione variÃ¡vel com â‰¥2 grupos")
        
        elif teste_tipo == "ANOVA (3+ grupos)":
            grupo_var = st.selectbox("ğŸ·ï¸ VariÃ¡vel grupos", cat_cols)
            grupos = df[grupo_var].dropna().unique()
            
            if len(grupos) >= 3 and st.button("ğŸ”¬ Executar ANOVA", type="primary"):
                grupo_dados = [df[df[grupo_var]==g][var_resposta].dropna() for g in grupos]
                f_stat, p_val = stats.f_oneway(*grupo_dados)
                
                col1, col2 = st.columns(2)
                col1.metric("F-statistic", f"{f_stat:.3f}")
                col2.metric("p-valor", f"{p_val:.4f}")
                
                if p_val < 0.05:
                    st.error(f"ğŸš¨ **REJEITA H0** - Pelo menos 1 grupo difere!")
                else:
                    st.success("â„¹ï¸ **NÃƒO rejeita H0** - Grupos similares")
        
        elif teste_tipo == "Qui-Quadrado":
            col1_var = st.selectbox("ğŸ·ï¸ VariÃ¡vel 1 (categÃ³rica)", cat_cols)
            col2_var = st.selectbox("ğŸ·ï¸ VariÃ¡vel 2 (categÃ³rica)", cat_cols)
            
            if st.button("ğŸ”¬ Executar Qui-Quadrado", type="primary"):
                contingency = pd.crosstab(df[col1_var], df[col2_var])
                chi2, p_val, dof, expected = stats.chi2_contingency(contingency)
                
                col1, col2 = st.columns(2)
                col1.metric("Ï‡Â²", f"{chi2:.3f}")
                col2.metric("p-valor", f"{p_val:.4f}")
                
                if p_val < 0.05:
                    st.error("ğŸš¨ **REJEITA H0** - VariÃ¡veis sÃ£o dependentes!")
                else:
                    st.success("â„¹ï¸ **NÃƒO rejeita** - VariÃ¡veis independentes")

    # =====================================
    # BARRA LATERAL: EXPORT
    # =====================================
    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸ’¾ Exportar")
    csv_bytes = convert_df(df)
    st.sidebar.download_button(
        "ğŸ“¥ Dados Originais CSV",
        csv_bytes,
        "dados_originais.csv",
        "text/csv"
    )

else:
    st.info("ğŸ‘† **Carregue CSV/Excel OU teste com dados automÃ¡ticos**")
    
    if st.button("ğŸ§ª Gerar Iris Dataset (teste)", type="primary"):
        st.info("ğŸ”„ Carregando Iris Dataset...")
        from sklearn.datasets import load_iris
        iris = load_iris()
        df_test = pd.DataFrame(iris.data, columns=iris.feature_names)
        df_test['target'] = iris.target
        st.session_state['uploaded_df'] = df_test
        st.success("âœ… **Iris Dataset carregado!** (150 amostras, 5 colunas)")
        st.rerun()
